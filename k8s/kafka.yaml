---
apiVersion: v1
kind: Service
metadata:
  name: kafka-service
  labels:
    app: kafka
spec:
  clusterIP: None
  ports:
    - name: kafka
      port: 9092
      targetPort: 9092
    - name: controller
      port: 9093
      targetPort: 9093
  selector:
    app: kafka

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  labels:
    app: kafka
spec:
  serviceName: kafka-service
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      terminationGracePeriodSeconds: 30
      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.5.0
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9092
            - containerPort: 9093
          env:
            # IDs
            - name: KAFKA_NODE_ID
              value: "1"
            - name: CLUSTER_ID
              value: "6mQGq_JxT1avG9PyIuqTHQ"   # <-- replace with your generated ID

            # KRaft roles & quorum
            - name: KAFKA_PROCESS_ROLES
              value: "broker,controller"
            - name: KAFKA_CONTROLLER_LISTENER_NAMES
              value: "CONTROLLER"
            - name: KAFKA_CONTROLLER_QUORUM_VOTERS
              value: "1@kafka-0.kafka-service.default.svc.cluster.local:9093"

            # Listeners
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://:9092,CONTROLLER://:9093"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://kafka-0.kafka-service.default.svc.cluster.local:9092"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "PLAINTEXT"

            # Logs path (avoid mixing with other files)
            - name: KAFKA_LOG_DIRS
              value: "/var/lib/kafka/kraft-combined-logs"

            # Minimal broker config
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS
              value: "0"
            - name: KAFKA_MIN_INSYNC_REPLICAS
              value: "1"

            # Auto-create topics off (we'll create explicitly below)
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: "false"

          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka

        # Sidecar to create topics (no separate Job)
        - name: topic-init
          image: confluentinc/cp-kafka:7.5.0
          command: ["/bin/bash","-lc"]
          args:
            - |
              set -e
              BOOTSTRAP="kafka-0.kafka-service.default.svc.cluster.local:9092"
              echo "Waiting for broker at ${BOOTSTRAP} ..."
              for i in {1..60}; do
                /usr/bin/kafka-broker-api-versions --bootstrap-server ${BOOTSTRAP} && ok=1 && break || true
                sleep 2
              done
              if [ "${ok}" != "1" ]; then
                echo "Broker not reachable, exiting"
                exit 1
              fi

              create_topic() {
                local t="$1"
                /usr/bin/kafka-topics --bootstrap-server ${BOOTSTRAP} --create --if-not-exists \
                  --topic "$t" --partitions 3 --replication-factor 1 || true
              }

              create_topic "pos-events"
              create_topic "staff-shifts"
              create_topic "security-events"
              create_topic "inventory-counts"
              create_topic "anomaly-alerts"

              echo "Topics ensured."
              # keep the sidecar alive but idle
              tail -f /dev/null
          env:
            - name: KAFKA_LOG_DIRS
              value: "/var/lib/kafka/kraft-combined-logs"
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka
          # Start after the main container is up (not strictly guaranteed, but fine)
          # Alternatively, you could use readiness gates.

      volumes: []
  volumeClaimTemplates:
    - metadata:
        name: kafka-data
        labels:
          app: kafka
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 5Gi

---
# Kafka UI (Provectus)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-ui
  labels:
    app: kafka-ui
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-ui
  template:
    metadata:
      labels:
        app: kafka-ui
    spec:
      containers:
        - name: kafka-ui
          image: provectuslabs/kafka-ui:latest
          ports:
            - containerPort: 8080
          env:
            - name: KAFKA_CLUSTERS_0_NAME
              value: "local"
            - name: KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS
              value: "kafka-0.kafka-service.default.svc.cluster.local:9092"
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-ui
spec:
  type: NodePort
  selector:
    app: kafka-ui
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 30090
